{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Links\n",
    "[Link von \"Pracitcal Statistics for Data Science\"](https://pandas.pydata.org/pandas-docs/stable/getting_started/dsintro.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "Alle Datensätze die man ggf braucht sind hier hinterlegt. für dieses Notebook lese ich mehrer Datensätze ein. Je nach Komplexitätsanforderung kann ich somit auf den entsprechenden zugreifen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datensätze Einlesen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Advertisment\n",
    "advertismentData=pd.read_csv('./Sample-Projects//ISLR/data/islrData_advertising.csv',delimiter=',',encoding='utf-8')\n",
    "advertismentData = advertismentData.drop(['Unnamed: 0'], axis=1)\n",
    "#advertismentData.head()\n",
    "\n",
    "#IrisDataSet\n",
    "irisData = pd.read_csv('./Sample-Projects/Iris/data/iris.data',delimiter=',',encoding='utf-8')\n",
    "irisData.columns = ['SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm','Species']\n",
    "#irisData.head()\n",
    "\n",
    "# cars\n",
    "labelList=['symboling','normalizedLosses','make','fuelType','aspiration','numOfDoors','bodyStyle','driveWheels','engineLocation',\n",
    "           'wheelBase','length','width','height','curbWeight','engineType','numOfCylinders','engineSize','fuelSystem','bore',\n",
    "           'stroke','compressionRatio','horsepower','peakRpm','cityMpg','highwayMpg','price']\n",
    "carDF = pd.read_csv('./data/data_car.csv',delimiter=',',encoding='utf-8', names=labelList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basicinfo über ein eingelesenes Dataset"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "carDF.info()\n",
    "carDF.isna().any()\n",
    "carDF.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Werte ersetzen / replace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "## nur in einer spezfischen Zeile\n",
    "carDF['bore'] = carDF['bore'].replace(\"?\", np.nan)\n",
    "print(type(carDF))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GesamtDatensatz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "carDF = carDF.replace(\"?\", np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change Datatype von Spalte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "carDF[['price']]=carDF[['price']].astype('float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ...to Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Numpyarr = carDF.to_numpy()\n",
    "'''print(type(carDF))\n",
    "print(type(Numpyarr))\n",
    "print(Numpyarr) ''' \n",
    "\n",
    "# hierbei gehen eben die Titel verolren => muss man sich wieder über die Column reinholen\n",
    "backToPandas =  pd.DataFrame(Numpyarr)\n",
    "#print(backToPandas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Erstelle eigenes Pandas-DF\n",
    "wenn nicht eingelesen kann man den auch aus den Python datentypen überführen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataframe out of own Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0   1\n",
      "0   tom  10\n",
      "1  nick  15\n",
      "2  juli  14\n"
     ]
    }
   ],
   "source": [
    "OwnData = [['tom', 10], ['nick', 15], ['juli', 14]] \n",
    "OwnDF = pd.DataFrame(OwnData) # DF für die Transofmationen des DF\n",
    "df = pd.DataFrame(OwnData) # Später bei renaming wichtig dass nur zwei spalten sind\n",
    "print(OwnDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataframe & add Column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Name  Age\n",
      "0   tom   10\n",
      "1  nick   15\n",
      "2  juli   14\n"
     ]
    }
   ],
   "source": [
    "# alternativ kann auch direkt ins df die Spalten hinzugefügt werden\n",
    "OwnDF.columns = ['Name', 'Age']\n",
    "print(OwnDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Füge Spalte hinzu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simpel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Name  Age FamilyName\n",
      "0   tom   10      Smith\n",
      "1  nick   15      Mayer\n",
      "2  juli   14     Christ\n",
      "   Name  Age FamilyName  housenumber\n",
      "0   tom   10      Smith            9\n",
      "1  nick   15      Mayer            6\n",
      "2  juli   14     Christ            3\n"
     ]
    }
   ],
   "source": [
    "#Kategorisch\n",
    "FamilyName = ['Smith', 'Mayer', 'Christ']\n",
    "OwnDF[\"FamilyName\"]=FamilyName\n",
    "print(OwnDF)\n",
    "# Numerisch\n",
    "housenumber = [9,6,3]\n",
    "OwnDF[\"housenumber\"]=housenumber\n",
    "print(OwnDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complex = Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculation with CONSTANT and Variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Name  Age FamilyName  housenumber  ageInFiveYears\n",
      "0   tom   10      Smith            9              15\n",
      "1  nick   15      Mayer            6              20\n",
      "2  juli   14     Christ            3              19\n"
     ]
    }
   ],
   "source": [
    "ageInFiveYears = OwnDF.Age + 5\n",
    "OwnDF[\"ageInFiveYears\"]=ageInFiveYears\n",
    "print(OwnDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculation with VARIABLE and Variable \n",
    "// gibt zwar kein sinn hausnummer mit alter zu verechnen, aber derweil egal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Name  Age FamilyName  housenumber  ageInFiveYears  AgeTimesHousenumber\n",
      "0   tom   10      Smith            9              15                   90\n",
      "1  nick   15      Mayer            6              20                   90\n",
      "2  juli   14     Christ            3              19                   42\n"
     ]
    }
   ],
   "source": [
    "AgeTimesHousenumber = OwnDF.Age * OwnDF.housenumber\n",
    "OwnDF[\"AgeTimesHousenumber\"]=AgeTimesHousenumber\n",
    "print(OwnDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Column Names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get Column names as list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('########Version 1########')\n",
    "for col in OwnDF.columns: \n",
    "    print(col) \n",
    "print()\n",
    "print('########Version 2########')\n",
    "#Version 2 mit integrated Function\n",
    "print(OwnDF.columns)\n",
    "print(OwnDF.columns[0])\n",
    "print(OwnDF.columns[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace Column Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('########Version1########')\n",
    "'''\n",
    "hier werden alle spalten geändert\n",
    "'''\n",
    "newColumnList = ['FirstName', 'Years since Birth']\n",
    "df.columns = newColumnList\n",
    "print(df)\n",
    "print()\n",
    "print('########Version2########')\n",
    "'''\n",
    "hier werden alle spalten geändert\n",
    "'''\n",
    "df.rename(columns={'FirstName':'nickname', \n",
    "                   'Years since Birth':'age'}, \n",
    "                 inplace=True)\n",
    "print(df)\n",
    "print()\n",
    "print('########Version3########')\n",
    "'''\n",
    "hier wird lediglich eine Spalte geändert\n",
    "'''\n",
    "df.rename(columns={'nickname':'Name'}, \n",
    "                 inplace=True) \n",
    "print(df)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtern\n",
    "um ein DF nach welchen Kriterien auch immer zu filtern habe ich grundsätzlich mehrere Möglichkeiten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loc & Iloc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loc / Zeilen filtern\n",
    "mit dem Loc kann ich nach Bedingungen innerhalb eines Features filtern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bedingung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hier alle größer als bestimmter wert in TV\n",
    "advertismentDataLoc = advertismentData.loc[\n",
    "    (advertismentData.TV > 40)]\n",
    "print(advertismentData.shape)\n",
    "print(advertismentDataLoc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hier alle größer als bestimmter wert in TV UND größer in Radio\n",
    "advertismentDataLoc2 = advertismentData.loc[\n",
    "    (advertismentData.TV > 40) & (advertismentData.radio > 40)]\n",
    "print(advertismentData.shape)\n",
    "print(advertismentDataLoc2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top \"whatever\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "advertismentDataLoc3 = advertismentData.loc[:99]\n",
    "print(advertismentData.shape)\n",
    "print(advertismentDataLoc3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iloc / Spalten filtern\n",
    "hiermir können Spalten nach numerischen Werten gefiltert werden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputFeature = [0,1,2]\n",
    "outputFeature = [3]\n",
    "input_df = advertismentData.iloc[:,inputFeature]\n",
    "output_df = advertismentData.iloc[:,outputFeature]\n",
    "print(advertismentData.shape)\n",
    "print(input_df.shape)\n",
    "print(output_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select / Reshape Data\n",
    "\n",
    "hier wollen ein unter Subset-Bilden. Ziel ist es aus einem Datensatz mit n feature einen neuen datensatz mit n-\"WelcheAnzahlAuchImmter\" zu bilden. Anders ausgedrückt, wir wollen nur bestimmte SPALTEN herauspicken. \n",
    "\n",
    "Wollen wir nur bestimmte ZEILEN auswählen, so muss man einen Filter/Subset wählen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version1 dropping obsolet data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTv = advertismentData.drop(['TV','radio','newspaper'], axis=1)\n",
    "print(dfTv.shape) # => es ist wichtig dass hier (200,1) und nicht (200, ) steht"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version 2  Transform into NP & reshaping the format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Long Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTv = advertismentData['TV']\n",
    "print(dfTv.shape) # => hier eben das Problem das oben bereit erwähnt wurde => (200, ) \n",
    "dfTv = dfTv.values.reshape(-1,1)\n",
    "print(dfTv.shape) # => hier eben das Problem das oben bereit erwähnt wurde => (200, ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Short Version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Single-Select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTv = advertismentData['TV'].values.reshape(-1,1)\n",
    "#print(dfTv)\n",
    "print(dfTv.shape)\n",
    "print(type(dfTv))\n",
    "print(type(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Multi-Select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTvRadio = advertismentData[['TV', 'radio']].values.reshape(-1,2)\n",
    "dfTvRadio2 = pd.DataFrame(dfTvRadio, columns = ['TV', 'Radio']) \n",
    "#dfTvRadio2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsets / Filter\n",
    "hier wollen ein unter Subset-Bilden. Ziel ist es bspw nur die \"Iris-versicolor\" aus dem IRIS-Dataset zu haben\n",
    "Das Subset kann man sich vorstellen wie ein Filter auf die Zeilen. Möchte man die Spalten Filtern(auswahl nur bestimmter Feature so muss nur diese Auswählen)so muss nur diese Auswählen. Kluger satz. Das mach ich in diesem Notebook unter dem Punkt \"Select/Reshape Data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter for numerical Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(irisData.describe()) # mean SepalLengthCm  =5.848322"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filteredSmallerThanMeanSepalLengthCM = irisData.loc[irisData['SepalLengthCm'] > 6] # <= hier kann die Zahl geändert werden\n",
    "print(filteredSmallerThanMeanSepalLengthCM.describe())\n",
    "print(filteredSmallerThanMeanSepalLengthCM.shape)\n",
    "print(irisData.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter for categorical Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#carDF.loc[carDF['make'] == 'audi']\n",
    "filteredforIrisVersicolor  = irisData.loc[iris['Species'] == 'Iris-versicolor']\n",
    "#print(filteredforIrisVersicolor)\n",
    "print(iris.Species.unique())\n",
    "print(filteredforIrisVersicolor.Species.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sort Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sortieren eines Vektors /SingleColumnDF/PandasSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSingleColumUNSORTED = advertismentData['TV']\n",
    "dfSingleColumSORTED = dfSingleColumUNSORTED.sort_values(ascending=True)\n",
    "#print(dfSingleColumUNSORTED)\n",
    "#print(dfSingleColumSORTED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sortieren eines Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Einzelnes Feature für Sortierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSortedforTv = advertismentData.sort_values(['TV'], ascending=True)\n",
    "print(df.head(5))\n",
    "print(dfSortedforTv.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mehrere Feature für Sortierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(irisData.head(5))\n",
    "dfSortedSpecies = irisData.sort_values(['SepalWidthCm', 'Species' ], ascending=[True, True])\n",
    "print(dfSortedSpecies.head(5))\n",
    "dfSortedSpecies = irisData.sort_values(['SepalWidthCm', 'Species' ], ascending=[True, False])\n",
    "print(dfSortedSpecies.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hat noch nicht geklappt, wenn ich das brauch hier die Solution hinzfügen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ausprägungen eines Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BSP-Iris-Data\n",
    "print(irisData.Species.unique())\n",
    "irisNames = list(irisData['Species'].unique())\n",
    "print(irisNames)\n",
    "print(type(irisNames))\n",
    "print(len(irisNames))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 unterschiedliche Dataframes\n",
    "hier werden die DF aneinandergereiht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# erstellen der zwei dataframes\n",
    "dataA = [['tom', 10], ['nick', 15], ['juli', 14]] \n",
    "dataB = [['Jochen', 117], ['Chris', 71], ['Silvia', 5]] \n",
    "dfA = pd.DataFrame(dataA, columns = ['Name', 'Age'])\n",
    "dfB = pd.DataFrame(dataB, columns = ['Name', 'Age'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Append // Sequenziell // Hintereinander hängen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inteaktion des Dataframes\n",
    "dfappend = dfA.append(dfB)\n",
    "print(dfappend)\n",
    "print(\"###################\")\n",
    "#update index for new dataframe\n",
    "dfappend = dfappend.reset_index()\n",
    "# Drop old index column\n",
    "dfappend = dfappend.drop(columns=\"index\")\n",
    "print(dfappend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## concat // parallel // nebeneinander hängen\n",
    "hier kann man mit den Column names sich natürlich besser spielen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#II concat => next to each other => rename / Überschreiebn\n",
    "dfconcat = pd.concat([dfA, dfB], axis=1, sort=False)\n",
    "print(dfconcat)\n",
    "print(\"###################\")\n",
    "dfconcat = pd.concat([dfA, dfB], axis=1, sort=False)\n",
    "dfconcat.columns = ['Name', 'Age', 'ParentsName', 'ParentsAge']\n",
    "print(dfconcat)\n",
    "\n",
    "# alternative für die Spalten namen || in diesem bsp halt doof, da hier die gleiche Sturktur (= jeweils Name', 'Age' vorliegt, \n",
    "# daher ist das eher ein bsp für sequentielle verbinung nicht parallel )\n",
    "newHeader = list(list(dfA.columns) + list(dfB.columns))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Füge Spalte zu Dataframe hinzu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfconcat[\"z\"]=1,2,3\n",
    "print(dfconcat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### !!! Meldung\n",
    "Ab hier brauche ich eine etwas komplexeres Datenset um klar zu machen, was ich hier tue. Die Schritte sind jedoch nach wievor unabhängig jeweils je Chunk(bzw abschnitt) unabhängig voneinander. Es geht lediglich darum die Konzepte zu verdeutlichen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#carDF.loc[carDF['make'] == 'audi']\n",
    "filteredcarDF = carDF.loc[carDF['horsepower'] == '?']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "320px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
